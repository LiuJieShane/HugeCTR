{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 25 05:14:30 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:07:00.0  On |                  N/A |\n",
      "| 41%   34C    P8    27W / 260W |    513MiB / 11010MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |################################| 748.8 MB 8.8 kB/s eta 0:00:018\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |################################| 68 kB 1.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.1)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |################################| 829 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=493275 sha256=5e4196d1bee1013a04cd167f5fe00655434aa1ae740a1b1bce0b8cd67703b39b\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "Successfully built future\n",
      "Installing collected packages: future, torch, tqdm\n",
      "Successfully installed future-0.18.2 torch-1.6.0 tqdm-4.48.2\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded.\n",
      "Need to get 167 kB of archives.\n",
      "After this operation, 558 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 unzip amd64 6.0-21ubuntu1 [167 kB]\n",
      "Fetched 167 kB in 2s (108 kB/s) \u001b[0m3m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 35606 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-21ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking unzip (6.0-21ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up unzip (6.0-21ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    " !pip3 install torch tqdm\n",
    "!apt install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p data\n",
    "cd data\n",
    "if [ ! -f \"ml-20m.zip\" ]; then\n",
    "    echo \"Downloading data\"\n",
    "    wget http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
    "    unzip ml-20m.zip\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-20m\tml-20m.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RATINGS = 20\n",
    "USER_COLUMN = 'userId'\n",
    "ITEM_COLUMN = 'movieId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TestNegSampler:\n",
    "    def __init__(self, train_ratings, nb_users, nb_items, nb_neg):\n",
    "        self.nb_neg = nb_neg\n",
    "        self.nb_users = nb_users \n",
    "        self.nb_items = nb_items \n",
    "\n",
    "        # compute unique ids for quickly created hash set and fast lookup\n",
    "        ids = (train_ratings[:, 0] * self.nb_items) + train_ratings[:, 1]\n",
    "        self.set = set(ids)\n",
    "\n",
    "    def generate(self, batch_size=128*1024):\n",
    "        users = torch.arange(0, self.nb_users).reshape([1, -1]).repeat([self.nb_neg, 1]).transpose(0, 1).reshape(-1)\n",
    "\n",
    "        items = [-1] * len(users)\n",
    "\n",
    "        random_items = torch.LongTensor(batch_size).random_(0, self.nb_items).tolist()\n",
    "        print('Generating validation negatives...')\n",
    "        for idx, u in enumerate(tqdm.tqdm(users.tolist())):\n",
    "            if not random_items:\n",
    "                random_items = torch.LongTensor(batch_size).random_(0, self.nb_items).tolist()\n",
    "            j = random_items.pop()\n",
    "            while u * self.nb_items + j in self.set:\n",
    "                if not random_items:\n",
    "                    random_items = torch.LongTensor(batch_size).random_(0, self.nb_items).tolist()\n",
    "                j = random_items.pop()\n",
    "\n",
    "            items[idx] = j\n",
    "        items = torch.LongTensor(items)\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out users with less than 20 ratings\n",
      "Mapping original user and item IDs to new sequential IDs\n",
      "Number of users: 138493\n",
      "Number of items: 26744\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/ml-20m/ratings.csv')\n",
    "print(\"Filtering out users with less than {} ratings\".format(MIN_RATINGS))\n",
    "grouped = df.groupby(USER_COLUMN)\n",
    "df = grouped.filter(lambda x: len(x) >= MIN_RATINGS)\n",
    "\n",
    "print(\"Mapping original user and item IDs to new sequential IDs\")\n",
    "df[USER_COLUMN], unique_users = pd.factorize(df[USER_COLUMN])\n",
    "df[ITEM_COLUMN], unique_items = pd.factorize(df[ITEM_COLUMN])\n",
    "\n",
    "nb_users = len(unique_users)\n",
    "nb_items = len(unique_items)\n",
    "\n",
    "print(\"Number of users: %d\\nNumber of items: %d\"%(len(unique_users), len(unique_items)))\n",
    "\n",
    "# Save the mapping to do the inference later on\n",
    "import pickle\n",
    "with open('./mappings.pickle', 'wb') as handle:\n",
    "    pickle.dump({\"users\": unique_users, \"items\": unique_items}, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-f5f2ded70be6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-f5f2ded70be6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Filtering out users with less than 20 ratings\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Filtering out users with less than 20 ratings\n",
    "Mapping original user and item IDs to new sequential IDs\n",
    "Number of users: 138493\n",
    "Number of items: 26744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to sort before popping to get last item\n",
    "df.sort_values(by='timestamp', inplace=True)\n",
    "    \n",
    "# clean up data\n",
    "del df['rating'], df['timestamp']\n",
    "df = df.drop_duplicates() # assuming it keeps order\n",
    "\n",
    "# now we have filtered and sorted by time data, we can split test data out\n",
    "grouped_sorted = df.groupby(USER_COLUMN, group_keys=False)\n",
    "test_data = grouped_sorted.tail(1).sort_values(by=USER_COLUMN)\n",
    "# need to pop for each group\n",
    "train_data = grouped_sorted.apply(lambda x: x.iloc[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  target\n",
       "20       0       20       1\n",
       "19       0       19       1\n",
       "86       0       86       1\n",
       "61       0       61       1\n",
       "23       0       23       1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target']=1\n",
    "test_data['target']=1\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 182699/69246500 [00:00<00:37, 1826983.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation negatives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69246500/69246500 [00:34<00:00, 2011692.29it/s]\n",
      "  1%|          | 172173/13849300 [00:00<00:07, 1721727.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation negatives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13849300/13849300 [00:07<00:00, 1903316.12it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler = _TestNegSampler(df.values, nb_users, nb_items, 500)  # using 500 negative samples\n",
    "train_negs = sampler.generate()\n",
    "train_negs = train_negs.reshape(-1, 500)\n",
    "\n",
    "sampler = _TestNegSampler(df.values, nb_users, nb_items, 100)  # using 100 negative samples\n",
    "test_negs = sampler.generate()\n",
    "test_negs = test_negs.reshape(-1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138493/138493 [03:14<00:00, 711.46it/s]\n",
      "100%|██████████| 138493/138493 [00:39<00:00, 3524.37it/s]\n"
     ]
    }
   ],
   "source": [
    " import numpy as np\n",
    "\n",
    "# generating negative samples for training\n",
    "train_data_neg = np.zeros((train_negs.shape[0]*train_negs.shape[1],3), dtype=int)\n",
    "idx = 0\n",
    "for i in tqdm.tqdm(range(train_negs.shape[0])):\n",
    "    for j in range(train_negs.shape[1]):\n",
    "        train_data_neg[idx, 0] = i # user ID\n",
    "        train_data_neg[idx, 1] = train_negs[i, j] # negative item ID\n",
    "        idx += 1\n",
    "    \n",
    "# generating negative samples for testing\n",
    "test_data_neg = np.zeros((test_negs.shape[0]*test_negs.shape[1],3), dtype=int)\n",
    "idx = 0\n",
    "for i in tqdm.tqdm(range(test_negs.shape[0])):\n",
    "    for j in range(test_negs.shape[1]):\n",
    "        test_data_neg[idx, 0] = i\n",
    "        test_data_neg[idx, 1] = test_negs[i, j]\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_np= np.concatenate([train_data_neg, train_data.values])\n",
    "np.random.shuffle(train_data_np)\n",
    "\n",
    "test_data_np= np.concatenate([test_data_neg, test_data.values])\n",
    "np.random.shuffle(test_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HugeCTR expect user ID and item ID to be different, so we use 0 -> nb_users for user IDs and\n",
    "# nb_users -> nb_users+nb_items for item IDs.\n",
    "train_data_np[:,1] += nb_users \n",
    "test_data_np[:,1] += nb_users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165236"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data_np[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import c_longlong as ll\n",
    "from ctypes import c_uint\n",
    "from ctypes import c_float\n",
    "from ctypes import c_int\n",
    "\n",
    "def write_hugeCTR_data(huge_ctr_data, filename='huge_ctr_data.dat'):\n",
    "    print(\"Writing %d samples\"%huge_ctr_data.shape[0])\n",
    "    with open(filename, 'wb') as f:\n",
    "        #write header\n",
    "        f.write(ll(0)) # 0: no error check; 1: check_num\n",
    "        f.write(ll(huge_ctr_data.shape[0])) # the number of samples in this data file\n",
    "        f.write(ll(1)) # dimension of label\n",
    "        f.write(ll(1)) # dimension of dense feature\n",
    "        f.write(ll(2)) # long long slot_num\n",
    "        for _ in range(3): f.write(ll(0)) # reserved for future use\n",
    "\n",
    "        for i in tqdm.tqdm(range(huge_ctr_data.shape[0])):\n",
    "            f.write(c_float(huge_ctr_data[i,2])) # float label[label_dim];\n",
    "            f.write(c_float(0)) # dummy dense feature\n",
    "            f.write(c_int(1)) # slot 1 nnz: user ID\n",
    "            f.write(c_uint(huge_ctr_data[i,0]))\n",
    "            f.write(c_int(1)) # slot 2 nnz: item ID\n",
    "            f.write(c_uint(huge_ctr_data[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8910827 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:15<00:00, 569455.41it/s]\n",
      "  1%|          | 54026/8910827 [00:00<00:16, 540256.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:16<00:00, 550378.05it/s]\n",
      "  1%|          | 53366/8910827 [00:00<00:16, 533657.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:16<00:00, 551115.16it/s]\n",
      "  1%|          | 105904/8910827 [00:00<00:16, 531623.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:16<00:00, 554014.34it/s]\n",
      "  1%|          | 54174/8910827 [00:00<00:16, 541730.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:15<00:00, 559359.69it/s]\n",
      "  1%|          | 54284/8910827 [00:00<00:16, 542832.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:16<00:00, 554242.17it/s]\n",
      "  0%|          | 0/8910827 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:16<00:00, 546928.65it/s]\n",
      "  1%|          | 54543/8910827 [00:00<00:16, 545427.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:16<00:00, 543786.90it/s]\n",
      "  1%|          | 52948/8910827 [00:00<00:16, 529475.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:16<00:00, 545660.84it/s]\n",
      "  1%|          | 54314/8910827 [00:00<00:16, 543139.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 8910827 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910827/8910827 [00:16<00:00, 552860.09it/s]\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./data/hugeCTR\n",
    "!mkdir ./data/hugeCTR\n",
    "\n",
    "for i, data_arr in enumerate(np.array_split(train_data_np,10)):\n",
    "    write_hugeCTR_data(data_arr, filename='./data/hugeCTR/huge_ctr_data_%d.dat'%i)\n",
    "    \n",
    "with open('./data/hugeCTR/filelist.txt', 'wt') as f:\n",
    "    f.write('10\\n');\n",
    "    for i in range(10):\n",
    "        f.write('./data/hugeCTR/huge_ctr_data_%d.dat\\n'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 51922/1398780 [00:00<00:02, 519211.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398780 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398780/1398780 [00:02<00:00, 552283.33it/s]\n",
      "  4%|▍         | 53758/1398780 [00:00<00:02, 537579.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398780 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398780/1398780 [00:02<00:00, 551534.86it/s]\n",
      "  4%|▍         | 53653/1398780 [00:00<00:02, 536521.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398780 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398780/1398780 [00:02<00:00, 552470.34it/s]\n",
      "  4%|▍         | 53929/1398779 [00:00<00:02, 539275.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398779 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398779/1398779 [00:02<00:00, 553955.85it/s]\n",
      "  4%|▍         | 53479/1398779 [00:00<00:02, 534785.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398779 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398779/1398779 [00:02<00:00, 565031.10it/s]\n",
      "  4%|▎         | 51775/1398779 [00:00<00:02, 517743.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398779 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398779/1398779 [00:02<00:00, 568308.39it/s]\n",
      "  4%|▍         | 55690/1398779 [00:00<00:02, 556891.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398779 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398779/1398779 [00:02<00:00, 572930.48it/s]\n",
      "  4%|▍         | 55724/1398779 [00:00<00:02, 557233.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398779 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398779/1398779 [00:02<00:00, 561832.12it/s]\n",
      "  4%|▍         | 53652/1398779 [00:00<00:02, 536512.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398779 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398779/1398779 [00:02<00:00, 549444.01it/s]\n",
      "  4%|▍         | 54115/1398779 [00:00<00:02, 541149.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1398779 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1398779/1398779 [00:02<00:00, 555207.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, data_arr in enumerate(np.array_split(test_data_np,10)):\n",
    "    write_hugeCTR_data(data_arr, filename='./data/hugeCTR/test_huge_ctr_data_%d.dat'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/hugeCTR/test_filelist.txt', 'wt') as f:\n",
    "    f.write('10\\n');\n",
    "    for i in range(10):\n",
    "        f.write('./data/hugeCTR/test_huge_ctr_data_%d.dat\\n'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dlrm_config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile dlrm_config.json\n",
    "{\n",
    "  \"solver\": {\n",
    "    \"lr_policy\": \"fixed\",\n",
    "    \"display\": 1000,\n",
    "    \"max_iter\":50000,\n",
    "    \"gpu\": [0],\n",
    "    \"batchsize\": 65536,\n",
    "    \"snapshot\": 3000,\n",
    "    \"snapshot_prefix\": \"./hugeCTR_saved_model_DLRM/\",\n",
    "    \"eval_interval\": 3000,\n",
    "    \"eval_batches\": 1000,\n",
    "    \"mixed_precision\": 1024,\n",
    "    \"eval_metrics\": [\"AUC:1.0\"]\n",
    "  },\n",
    " \n",
    "  \"optimizer\": {\n",
    "    \"type\": \"SGD\",\n",
    "    \"global_update\": false,\n",
    "    \"sgd_hparam\": {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"warmup_steps\": 1000,\n",
    "    \"decay_start\": 10000,\n",
    "    \"decay_steps\": 40000,\n",
    "    \"end_lr\": 1e-5\n",
    "    }\n",
    "  },\n",
    "\n",
    "\n",
    "  \"layers\": [ \n",
    "      {\n",
    "      \"name\": \"data\",\n",
    "      \"type\": \"Data\",\n",
    "      \"slot_size_array\": [138493 , 26744],\n",
    "      \"slot_size_array_orig\": [138493 , 26744],\n",
    "      \"source\": \"./data/hugeCTR/filelist.txt\",\n",
    "      \"eval_source\": \"./data/hugeCTR/test_filelist.txt\",\n",
    "      \"check\": \"None\",\n",
    "      \"cache_eval_data\": true,\n",
    "      \"label\": {\n",
    "              \"top\": \"label\",\n",
    "              \"label_dim\": 1\n",
    "      },\n",
    "      \"dense\": {\n",
    "              \"top\": \"dense\",\n",
    "              \"dense_dim\": 1\n",
    "      },\n",
    "      \"sparse\": [\n",
    "              {\n",
    "          \"top\": \"data1\",\n",
    "          \"type\": \"LocalizedSlot\",\n",
    "          \"max_feature_num_per_sample\": 2,\n",
    "          \"max_nnz\": 1,\n",
    "          \"slot_num\": 2\n",
    "              }\n",
    "      ]\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"sparse_embedding1\",\n",
    "      \"type\": \"LocalizedSlotSparseEmbeddingHash\",\n",
    "      \"bottom\": \"data1\",\n",
    "      \"top\": \"sparse_embedding1\",\n",
    "      \"sparse_embedding_hparam\": {\n",
    "        \"slot_size_array\": [138493 , 26744],\n",
    "        \"embedding_vec_size\": 64,\n",
    "        \"combiner\": 0\n",
    "      }\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"fc1\",\n",
    "      \"type\": \"FusedInnerProduct\",\n",
    "      \"bottom\": \"dense\",\n",
    "      \"top\": \"fc1\",\n",
    "      \"fc_param\": {\n",
    "        \"num_output\": 64\n",
    "      }\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"fc2\",\n",
    "      \"type\": \"FusedInnerProduct\",\n",
    "      \"bottom\": \"fc1\",\n",
    "      \"top\": \"fc2\",\n",
    "      \"fc_param\": {\n",
    "        \"num_output\": 128\n",
    "      }\n",
    "    },\n",
    "\n",
    "   \n",
    "    {\n",
    "      \"name\": \"fc3\",\n",
    "      \"type\": \"FusedInnerProduct\",\n",
    "      \"bottom\": \"fc2\",\n",
    "      \"top\": \"fc3\",\n",
    "      \"fc_param\": {\n",
    "        \"num_output\": 64\n",
    "      }\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"interaction1\",\n",
    "      \"type\": \"Interaction\",\n",
    "      \"bottom\": [\"fc3\", \"sparse_embedding1\"],\n",
    "      \"top\": \"interaction1\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"fc4\",\n",
    "      \"type\": \"FusedInnerProduct\",\n",
    "      \"bottom\": \"interaction1\",\n",
    "      \"top\": \"fc4\",\n",
    "       \"fc_param\": {\n",
    "        \"num_output\": 1024\n",
    "      }\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"fc5\",\n",
    "      \"type\": \"FusedInnerProduct\",\n",
    "      \"bottom\": \"fc4\",\n",
    "      \"top\": \"fc5\",\n",
    "      \"fc_param\": {\n",
    "        \"num_output\": 1024\n",
    "      }\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"fc6\",\n",
    "      \"type\": \"FusedInnerProduct\",\n",
    "      \"bottom\": \"fc5\",\n",
    "      \"top\": \"fc6\",\n",
    "      \"fc_param\": {\n",
    "        \"num_output\": 512\n",
    "      }\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"fc7\",\n",
    "      \"type\": \"FusedInnerProduct\",\n",
    "      \"bottom\": \"fc6\",\n",
    "      \"top\": \"fc7\",\n",
    "      \"fc_param\": {\n",
    "        \"num_output\": 256\n",
    "      }\n",
    "    },\n",
    "\n",
    "    {\n",
    "      \"name\": \"fc8\",\n",
    "      \"type\": \"InnerProduct\",\n",
    "      \"bottom\": \"fc7\",\n",
    "      \"top\": \"fc8\",\n",
    "      \"fc_param\": {\n",
    "        \"num_output\": 1\n",
    "      }\n",
    "    },\n",
    "    \n",
    "    {\n",
    "      \"name\": \"loss\",\n",
    "      \"type\": \"BinaryCrossEntropyLoss\",\n",
    "      \"bottom\": [\"fc8\",\"label\"],\n",
    "      \"top\": \"loss\"\n",
    "    } \n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./hugeCTR_saved_model_DLRM/\n",
    "!mkdir ./hugeCTR_saved_model_DLRM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ../build/bin/huge_ctr: not found\r\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 ../build/bin/huge_ctr --train ./dlrm_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, init_start, ]\n",
      "HugeCTR Version: 2.2.1\n",
      "Config file: ./dlrm_config.json\n",
      "[25d05h37m46s][HUGECTR][INFO]: batchsize_eval is not specified using default: 65536\n",
      "Mixed Precision training with scaler: 1024 is enabled.\n",
      "[25d05h37m46s][HUGECTR][INFO]: algorithm_search is not specified using default: 1\n",
      "[25d05h37m46s][HUGECTR][INFO]: Algorithm search: ON\n",
      "[25d05h37m49s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.\n",
      "Device 0: GeForce RTX 2080 Ti\n",
      "[25d05h37m49s][HUGECTR][INFO]: Initial seed is 622198320\n",
      "[25d05h37m49s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d05h37m49s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d05h37m49s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=165237\n",
      "[25d05h37m49s][HUGECTR][INFO]: All2All Warmup Start\n",
      "[25d05h37m49s][HUGECTR][INFO]: All2All Warmup End\n",
      "[25d05h38m21s][HUGECTR][INFO]: gpu0 start to init embedding of slot0 , slot_size=138493, key_offset=0, value_index_offset=0\n",
      "[25d05h38m21s][HUGECTR][INFO]: gpu0 start to init embedding of slot1 , slot_size=26744, key_offset=138493, value_index_offset=138493\n",
      "[25d05h38m21s][HUGECTR][INFO]: decay_power is not specified using default: 2.000000\n",
      "[35290.8, init_end, ]\n",
      "[35290.8, run_start, ]\n",
      "HugeCTR training start:\n",
      "[35290.8, train_epoch_start, 0, ]\n",
      "[25d05h38m43s][HUGECTR][INFO]: Iter: 1000 Time(1000 iters): 22.370355s Loss: 0.531467 lr:0.100000\n",
      "[25d05h39m06s][HUGECTR][INFO]: Iter: 2000 Time(1000 iters): 22.349353s Loss: 0.532283 lr:0.100000\n",
      "[25d05h39m27s][HUGECTR][INFO]: Iter: 3000 Time(1000 iters): 21.582700s Loss: 0.527995 lr:0.100000\n",
      "[25d05h39m27s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h39m27s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h39m27s][HUGECTR][INFO]: Done\n",
      "[101650, eval_start, 0.06, ]\n",
      "[25d05h39m36s][HUGECTR][INFO]: Evaluation, AUC: 0.501071\n",
      "[110706, eval_accuracy, 0.501071, 0.06, 3000, ]\n",
      "[25d05h39m36s][HUGECTR][INFO]: Eval Time for 1000 iters: 9.055596s\n",
      "[110706, eval_stop, 0.06, ]\n",
      "[25d05h39m59s][HUGECTR][INFO]: Iter: 4000 Time(1000 iters): 31.418654s Loss: 0.533765 lr:0.100000\n",
      "[25d05h40m22s][HUGECTR][INFO]: Iter: 5000 Time(1000 iters): 23.171800s Loss: 0.533554 lr:0.100000\n",
      "[25d05h40m44s][HUGECTR][INFO]: Iter: 6000 Time(1000 iters): 22.301218s Loss: 0.530814 lr:0.100000\n",
      "[25d05h40m44s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h40m44s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h40m44s][HUGECTR][INFO]: Done\n",
      "[178548, eval_start, 0.12, ]\n",
      "[25d05h40m53s][HUGECTR][INFO]: Evaluation, AUC: 0.558340\n",
      "[187126, eval_accuracy, 0.55834, 0.12, 6000, ]\n",
      "[25d05h40m53s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.578199s\n",
      "[187126, eval_stop, 0.12, ]\n",
      "[25d05h41m14s][HUGECTR][INFO]: Iter: 7000 Time(1000 iters): 30.154136s Loss: 0.526718 lr:0.100000\n",
      "[25d05h41m36s][HUGECTR][INFO]: Iter: 8000 Time(1000 iters): 22.005724s Loss: 0.532031 lr:0.100000\n",
      "[25d05h41m59s][HUGECTR][INFO]: Iter: 9000 Time(1000 iters): 22.584662s Loss: 0.530967 lr:0.100000\n",
      "[25d05h41m59s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h41m59s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h41m59s][HUGECTR][INFO]: Done\n",
      "[253288, eval_start, 0.18, ]\n",
      "[25d05h42m08s][HUGECTR][INFO]: Evaluation, AUC: 0.705444\n",
      "[262371, eval_accuracy, 0.705444, 0.18, 9000, ]\n",
      "[25d05h42m08s][HUGECTR][INFO]: Eval Time for 1000 iters: 9.083358s\n",
      "[262371, eval_stop, 0.18, ]\n",
      "[25d05h42m30s][HUGECTR][INFO]: Iter: 10000 Time(1000 iters): 30.714971s Loss: 0.535773 lr:0.099995\n",
      "[25d05h42m51s][HUGECTR][INFO]: Iter: 11000 Time(1000 iters): 21.595971s Loss: 0.528493 lr:0.095058\n",
      "[25d05h43m13s][HUGECTR][INFO]: Iter: 12000 Time(1000 iters): 21.637163s Loss: 0.528056 lr:0.090245\n",
      "[25d05h43m13s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h43m13s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h43m13s][HUGECTR][INFO]: Done\n",
      "[327235, eval_start, 0.24, ]\n",
      "[25d05h43m21s][HUGECTR][INFO]: Evaluation, AUC: 0.832274\n",
      "[335824, eval_accuracy, 0.832274, 0.24, 12000, ]\n",
      "[25d05h43m21s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.589097s\n",
      "[335824, eval_stop, 0.24, ]\n",
      "[25d05h43m43s][HUGECTR][INFO]: Iter: 13000 Time(1000 iters): 30.326403s Loss: 0.517088 lr:0.085558\n",
      "[25d05h44m05s][HUGECTR][INFO]: Iter: 14000 Time(1000 iters): 21.743143s Loss: 0.335788 lr:0.080996\n",
      "[25d05h44m27s][HUGECTR][INFO]: Iter: 15000 Time(1000 iters): 21.761964s Loss: 0.488366 lr:0.076558\n",
      "[25d05h44m27s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h44m27s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h44m27s][HUGECTR][INFO]: Done\n",
      "[401067, eval_start, 0.3, ]\n",
      "[25d05h44m35s][HUGECTR][INFO]: Evaluation, AUC: 0.941614\n",
      "[409676, eval_accuracy, 0.941614, 0.3, 15000, ]\n",
      "[25d05h44m35s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.608952s\n",
      "[409676, eval_stop, 0.3, ]\n",
      "[25d05h44m58s][HUGECTR][INFO]: Iter: 16000 Time(1000 iters): 30.903749s Loss: 0.500300 lr:0.072246\n",
      "[25d05h45m19s][HUGECTR][INFO]: Iter: 17000 Time(1000 iters): 21.861636s Loss: 0.448063 lr:0.068058\n",
      "[25d05h45m41s][HUGECTR][INFO]: Iter: 18000 Time(1000 iters): 21.774058s Loss: 0.499635 lr:0.063996\n",
      "[25d05h45m41s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h45m41s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h45m41s][HUGECTR][INFO]: Done\n",
      "[475607, eval_start, 0.36, ]\n",
      "[25d05h45m50s][HUGECTR][INFO]: Evaluation, AUC: 0.946793\n",
      "[484292, eval_accuracy, 0.946793, 0.36, 18000, ]\n",
      "[25d05h45m50s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.685193s\n",
      "[484292, eval_stop, 0.36, ]\n",
      "[25d05h46m12s][HUGECTR][INFO]: Iter: 19000 Time(1000 iters): 30.501675s Loss: 0.298419 lr:0.060059\n",
      "[25d05h46m33s][HUGECTR][INFO]: Iter: 20000 Time(1000 iters): 21.766116s Loss: 0.470993 lr:0.056246\n",
      "[25d05h46m55s][HUGECTR][INFO]: Iter: 21000 Time(1000 iters): 21.810883s Loss: 0.454951 lr:0.052559\n",
      "[25d05h46m55s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h46m55s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h46m55s][HUGECTR][INFO]: Done\n",
      "[549688, eval_start, 0.42, ]\n",
      "[25d05h47m04s][HUGECTR][INFO]: Evaluation, AUC: 0.947471\n",
      "[558349, eval_accuracy, 0.947471, 0.42, 21000, ]\n",
      "[25d05h47m04s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.660829s\n",
      "[558349, eval_stop, 0.42, ]\n",
      "[25d05h47m26s][HUGECTR][INFO]: Iter: 22000 Time(1000 iters): 30.976047s Loss: 0.235792 lr:0.048997\n",
      "[25d05h47m48s][HUGECTR][INFO]: Iter: 23000 Time(1000 iters): 21.917770s Loss: 0.459210 lr:0.045559\n",
      "[25d05h48m11s][HUGECTR][INFO]: Iter: 24000 Time(1000 iters): 22.355545s Loss: 0.489652 lr:0.042247\n",
      "[25d05h48m11s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h48m11s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h48m11s][HUGECTR][INFO]: Done\n",
      "[624937, eval_start, 0.48, ]\n",
      "[25d05h48m19s][HUGECTR][INFO]: Evaluation, AUC: 0.947906\n",
      "[633751, eval_accuracy, 0.947906, 0.48, 24000, ]\n",
      "[25d05h48m19s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.813756s\n",
      "[633751, eval_stop, 0.48, ]\n",
      "[25d05h48m42s][HUGECTR][INFO]: Iter: 25000 Time(1000 iters): 31.081699s Loss: 0.416488 lr:0.039059\n",
      "[25d05h49m04s][HUGECTR][INFO]: Iter: 26000 Time(1000 iters): 22.190632s Loss: 0.537747 lr:0.035997\n",
      "[25d05h49m26s][HUGECTR][INFO]: Iter: 27000 Time(1000 iters): 22.002859s Loss: 0.318125 lr:0.033060\n",
      "[25d05h49m26s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h49m26s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h49m26s][HUGECTR][INFO]: Done\n",
      "[700212, eval_start, 0.54, ]\n",
      "[25d05h49m34s][HUGECTR][INFO]: Evaluation, AUC: 0.948121\n",
      "[708840, eval_accuracy, 0.948121, 0.54, 27000, ]\n",
      "[25d05h49m34s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.628515s\n",
      "[708840, eval_stop, 0.54, ]\n",
      "[25d05h49m56s][HUGECTR][INFO]: Iter: 28000 Time(1000 iters): 30.461156s Loss: 0.425884 lr:0.030247\n",
      "[25d05h50m18s][HUGECTR][INFO]: Iter: 29000 Time(1000 iters): 21.768500s Loss: 0.462778 lr:0.027560\n",
      "[25d05h50m40s][HUGECTR][INFO]: Iter: 30000 Time(1000 iters): 21.763849s Loss: 0.407274 lr:0.024998\n",
      "[25d05h50m40s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h50m40s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h50m40s][HUGECTR][INFO]: Done\n",
      "[774205, eval_start, 0.6, ]\n",
      "[25d05h50m49s][HUGECTR][INFO]: Evaluation, AUC: 0.948138\n",
      "[782847, eval_accuracy, 0.948138, 0.6, 30000, ]\n",
      "[25d05h50m49s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.642119s\n",
      "[782847, eval_stop, 0.6, ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25d05h51m11s][HUGECTR][INFO]: Iter: 31000 Time(1000 iters): 30.729972s Loss: 0.441372 lr:0.022560\n",
      "[25d05h51m33s][HUGECTR][INFO]: Iter: 32000 Time(1000 iters): 22.173480s Loss: 0.497072 lr:0.020248\n",
      "[25d05h51m55s][HUGECTR][INFO]: Iter: 33000 Time(1000 iters): 22.115791s Loss: 0.436466 lr:0.018060\n",
      "[25d05h51m55s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h51m55s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h51m55s][HUGECTR][INFO]: Done\n",
      "[849223, eval_start, 0.66, ]\n",
      "[25d05h52m04s][HUGECTR][INFO]: Evaluation, AUC: 0.948253\n",
      "[857946, eval_accuracy, 0.948253, 0.66, 33000, ]\n",
      "[25d05h52m04s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.723772s\n",
      "[857946, eval_stop, 0.66, ]\n",
      "[25d05h52m25s][HUGECTR][INFO]: Iter: 34000 Time(1000 iters): 30.597599s Loss: 0.424306 lr:0.015998\n",
      "[25d05h52m47s][HUGECTR][INFO]: Iter: 35000 Time(1000 iters): 21.771958s Loss: 0.433659 lr:0.014061\n",
      "[25d05h53m09s][HUGECTR][INFO]: Iter: 36000 Time(1000 iters): 21.774109s Loss: 0.425400 lr:0.012248\n",
      "[25d05h53m09s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h53m09s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h53m09s][HUGECTR][INFO]: Done\n",
      "[923366, eval_start, 0.72, ]\n",
      "[25d05h53m18s][HUGECTR][INFO]: Evaluation, AUC: 0.948312\n",
      "[932032, eval_accuracy, 0.948312, 0.72, 36000, ]\n",
      "[25d05h53m18s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.666111s\n",
      "[932032, eval_stop, 0.72, ]\n",
      "[25d05h53m39s][HUGECTR][INFO]: Iter: 37000 Time(1000 iters): 30.494286s Loss: 0.416441 lr:0.010561\n",
      "[25d05h54m01s][HUGECTR][INFO]: Iter: 38000 Time(1000 iters): 21.946214s Loss: 0.438117 lr:0.008999\n",
      "[25d05h54m23s][HUGECTR][INFO]: Iter: 39000 Time(1000 iters): 21.827342s Loss: 0.312911 lr:0.007561\n",
      "[25d05h54m23s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h54m23s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h54m23s][HUGECTR][INFO]: Done\n",
      "[997634, eval_start, 0.78, ]\n",
      "[25d05h54m32s][HUGECTR][INFO]: Evaluation, AUC: 0.948445\n",
      "[1.00628e+06, eval_accuracy, 0.948445, 0.78, 39000, ]\n",
      "[25d05h54m32s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.642385s\n",
      "[1.00628e+06, eval_stop, 0.78, ]\n",
      "[25d05h54m54s][HUGECTR][INFO]: Iter: 40000 Time(1000 iters): 30.480326s Loss: 0.488520 lr:0.006249\n",
      "[25d05h55m16s][HUGECTR][INFO]: Iter: 41000 Time(1000 iters): 21.809279s Loss: 0.506320 lr:0.005061\n",
      "[25d05h55m38s][HUGECTR][INFO]: Iter: 42000 Time(1000 iters): 22.702866s Loss: 0.283231 lr:0.003999\n",
      "[25d05h55m38s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h55m38s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h55m38s][HUGECTR][INFO]: Done\n",
      "[1.07263e+06, eval_start, 0.84, ]\n",
      "[25d05h55m47s][HUGECTR][INFO]: Evaluation, AUC: 0.948365\n",
      "[1.08145e+06, eval_accuracy, 0.948365, 0.84, 42000, ]\n",
      "[25d05h55m47s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.818326s\n",
      "[1.08145e+06, eval_stop, 0.84, ]\n",
      "[25d05h56m09s][HUGECTR][INFO]: Iter: 43000 Time(1000 iters): 30.845797s Loss: 0.302953 lr:0.003062\n",
      "[25d05h56m31s][HUGECTR][INFO]: Iter: 44000 Time(1000 iters): 21.787678s Loss: 0.505121 lr:0.002249\n",
      "[25d05h56m53s][HUGECTR][INFO]: Iter: 45000 Time(1000 iters): 21.787065s Loss: 0.407523 lr:0.001562\n",
      "[25d05h56m53s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h56m53s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h56m53s][HUGECTR][INFO]: Done\n",
      "[1.14705e+06, eval_start, 0.9, ]\n",
      "[25d05h57m01s][HUGECTR][INFO]: Evaluation, AUC: 0.948533\n",
      "[1.15567e+06, eval_accuracy, 0.948533, 0.9, 45000, ]\n",
      "[25d05h57m01s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.627349s\n",
      "[1.15567e+06, eval_stop, 0.9, ]\n",
      "[25d05h57m23s][HUGECTR][INFO]: Iter: 46000 Time(1000 iters): 30.474556s Loss: 0.530183 lr:0.001000\n",
      "[25d05h57m45s][HUGECTR][INFO]: Iter: 47000 Time(1000 iters): 21.782335s Loss: 0.431085 lr:0.000562\n",
      "[25d05h58m07s][HUGECTR][INFO]: Iter: 48000 Time(1000 iters): 21.777980s Loss: 0.432111 lr:0.000250\n",
      "[25d05h58m07s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[25d05h58m07s][HUGECTR][INFO]: Rank0: Write hash table <key,value> pairs to file\n",
      "[25d05h58m07s][HUGECTR][INFO]: Done\n",
      "[1.22108e+06, eval_start, 0.96, ]\n",
      "[25d05h58m15s][HUGECTR][INFO]: Evaluation, AUC: 0.948402\n",
      "[1.22971e+06, eval_accuracy, 0.948402, 0.96, 48000, ]\n",
      "[25d05h58m15s][HUGECTR][INFO]: Eval Time for 1000 iters: 8.624586s\n",
      "[1.22971e+06, eval_stop, 0.96, ]\n",
      "[25d05h58m37s][HUGECTR][INFO]: Iter: 49000 Time(1000 iters): 30.462626s Loss: 0.493622 lr:0.000062\n",
      "[1.27328e+06, train_epoch_end, 1, ]\n",
      "[1.27328e+06, run_stop, ]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 ./build/bin/huge_ctr --train ./dlrm_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "key_type = 'I32' # {'I64', 'I32'}, default is 'I32'\n",
    "key_type_map = {\"I32\": [\"I\", 4], \"I64\": [\"q\", 8]}\n",
    "\n",
    "embedding_vec_size = 64\n",
    "each_key_size = key_type_map[key_type][1] + key_type_map[key_type][1] + 4 * embedding_vec_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slot ID not found - 52682\n"
     ]
    }
   ],
   "source": [
    "embedding_table = [{},{}]\n",
    "\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb') as file:\n",
    "    try:\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            \n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-eaa9fa22b3fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mitem_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m26744\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_vec_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mitem_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "item_embedding = np.zeros((26744, embedding_vec_size), dtype='float')\n",
    "for i in range(len(embedding_table[1])):\n",
    "    item_embedding[i] = embedding_table[1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slot ID not found - 23060\n"
     ]
    }
   ],
   "source": [
    "embedding_table = [{},{}]\n",
    "\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_48000.model', 'rb') as file:\n",
    "    try:\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            \n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def find_similar_movies(nn_movie_id, item_embedding, k=10, metric=\"euclidean\"):\n",
    "    #find the top K similar items according to one of the distance metric: cosine or euclidean\n",
    "    sim = 1-cdist(item_embedding, item_embedding[nn_movie_id].reshape(1, -1), metric=metric)\n",
    "   \n",
    "    return sim.squeeze().argsort()[-k:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./mappings.pickle', 'rb') as handle:\n",
    "    movies_mapping = pickle.load(handle)[\"items\"]\n",
    "\n",
    "nn_to_movies = movies_mapping\n",
    "movies_to_nn = {}\n",
    "for i in range(len(movies_mapping)):\n",
    "    movies_to_nn[movies_mapping[i]] = i\n",
    "\n",
    "import pandas as pd\n",
    "movies = pd.read_csv(\"./data/ml-20m/movies.csv\", index_col=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  Toy Story (1995) Adventure|Animation|Children|Comedy|Fantasy\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Jumanji (1995) Adventure|Children|Fantasy\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Grumpier Old Men (1995) Comedy|Romance\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Waiting to Exhale (1995) Comedy|Drama|Romance\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Father of the Bride Part II (1995) Comedy\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Heat (1995) Action|Crime|Thriller\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Sabrina (1995) Comedy|Romance\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Tom and Huck (1995) Adventure|Children\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Sudden Death (1995) Action\n",
      "Similar movies: \n",
      "110510 Série noire (1979) Film-Noir\n",
      "84553 Pekka ja Pätkä salapoliiseina (1957) Comedy\n",
      "27238 Guest House Paradiso (1999) Comedy|Thriller\n",
      "27450 Blueberry (2004) Adventure|Western\n",
      "27643 Pahat pojat (2003) Action|Crime|Drama\n",
      "27751 'Salem's Lot (2004) Drama|Horror|Mystery|Thriller\n",
      "30791 Hellraiser: Inferno (2000) Horror\n",
      "31255 Ice Station Zebra (1968) Action|Thriller\n",
      "31617 El Cid (1961) Action|Adventure|Drama|Romance|War\n",
      "32263 Vares: Private Eye (Vares - Yksityisetsivä) (2004) Action|Comedy|Crime|Thriller\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie_ID in range(1,10):\n",
    "    try:\n",
    "        print(\"Query: \", movies.loc[movie_ID][\"title\"], movies.loc[movie_ID][\"genres\"])\n",
    "\n",
    "        print(\"Similar movies: \")\n",
    "        similar_movies = find_similar_movies(movies_to_nn[movie_ID], item_embedding)\n",
    "\n",
    "        for i in similar_movies:\n",
    "            print(nn_to_movies[i], movies.loc[nn_to_movies[i]][\"title\"], movies.loc[nn_to_movies[i]][\"genres\"])\n",
    "        print(\"=================================\\n\")\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slot ID not found - 52682\n"
     ]
    }
   ],
   "source": [
    "embedding_table = [{},{}]\n",
    "\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb') as file:\n",
    "    try:\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            \n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embedding = np.zeros((26744, embedding_vec_size), dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5bac28cd7aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mitem_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i in range(len(embedding_table[1])):\n",
    "    item_embedding[i] = embedding_table[1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_table[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vec_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = file.read(each_key_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-7a13ecb0117f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "len(buffer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'p$\\x02\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00,y\\xc2\\xba/\\xc9k;h=\\xaf:\\xf1\\xffE;\\xbf\\x8c\\xba\\xba\\xf78e\\xbb6\\n\\xb1:\\xfe\\x99\\xc8;x\\xe6\\xd4\\xbam; \\xbb(\\x95\\x87\\xbb}\\x8c6\\xbb\\xc2\\x9e7\\xbb\\xd7\\xae(\\xbb/\\x9f;\\xbb}\\x94\\x8d;\\xc0\\x99\\x88\\xba\\x8a%\\x15\\xbb\\xa96t\\xbb&\\x8f\\x04\\xbbu_#98\\x9f\\x0f;\\xd1,\\x8a;`Q\\x8a:\\x9a\\x969;\\xc7`k:\\xbd\\xc0\\x11;\\xf0\\xfa\\x9d;3k\\x01\\xb9p\\x94\\xdb:\\x8b\\x8c\\x1a;\\x16,\\t;\\x96\\x946\\xbb\\xb1\\x16\\x86;\\xe3\\xb0\\x8b:X\\xe4)9\\xac/\\xc0:\\xc2?\\xbc\\xbb\\x15z\\x97;C$^\\xbb^}Z\\xbb8!\\x0b\\xbb\\ns\\xe1:\\x9e\\xb1\\x85\\xbb\\xdfX\\xc4;HE\\xdb\\xb9\\x15*\\xcb;-\\x91=;\\xfe\\xdb\\xaf\\xbb\\x00\\xdf\\x84\\xbb\\x9a]@;`\\x03\\x93\\xba\\xaf\\xef}\\xb9\\x9d\\x16\\xa1;h\\xf9\\x07;y\\x17\\xbb;\\\\\\xd4\\xc2\\xbb\\xea`e;\\x98\\xf6p:\\xa9&\\xbc\\xbbh\\x81\\r;V\\xf3\\xbd\\xba\"\\x98H\\xbb'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 140400 (0.0, -0.0014837137423455715, 0.0035978069063276052, 0.0013369740918278694, 0.003021236741915345, -0.0014232619432732463, -0.0034976580645889044, 0.0013507071416825056, 0.006121872924268246, -0.0016243001446127892, -0.0024449483025819063, -0.004137653857469559, -0.0027854733634740114, -0.0028018211014568806, -0.0025738978292793036, -0.002862881636247039, 0.004320679698139429, -0.0010421797633171082, -0.0022757970727980137, -0.0037264025304466486, -0.0020226924680173397, 0.00015580451872665435, 0.0021914970129728317, 0.004216768313199282, 0.0010552816092967987, 0.0028318525291979313, 0.0008978959522210062, 0.0022240125108510256, 0.004821173846721649, -0.00012342333502601832, 0.0016752611845731735, 0.0023582305293530226, 0.0020930818282067776, -0.002785956021398306, 0.004092060495167971, 0.001065757474862039, 0.00016202160622924566, 0.001466264482587576, -0.005744905211031437, 0.004622707609087229, -0.003389612538740039, -0.0033338884823024273, -0.0021229516714811325, 0.0017200422007590532, -0.004080011509358883, 0.005992039572447538, -0.00041822553612291813, 0.006200084928423166, 0.002892564283683896, -0.005366801284253597, -0.004054903984069824, 0.002935266587883234, -0.0011216215789318085, -0.0002421724930172786, 0.0049160257913172245, 0.0020748022943735123, 0.005709585268050432, -0.005945725366473198, 0.0035000392235815525, 0.0009192018769681454, -0.005741913337260485, 0.0021592024713754654, -0.001449207542464137, -0.0030608256347477436)\n",
      "\n",
      "\n",
      "Slot ID not found - 52682\n"
     ]
    }
   ],
   "source": [
    "embedding_table = [{},{}]\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb') as file:\n",
    "    try:\n",
    "        i = 0\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            print(i, slot_id, key, values)\n",
    "            print(\"\\n\")\n",
    "            i+=1\n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 140400 (0.0, -0.0014837137423455715, 0.0035978069063276052, 0.0013369740918278694, 0.003021236741915345, -0.0014232619432732463, -0.0034976580645889044, 0.0013507071416825056, 0.006121872924268246, -0.0016243001446127892, -0.0024449483025819063, -0.004137653857469559, -0.0027854733634740114, -0.0028018211014568806, -0.0025738978292793036, -0.002862881636247039, 0.004320679698139429, -0.0010421797633171082, -0.0022757970727980137, -0.0037264025304466486, -0.0020226924680173397, 0.00015580451872665435, 0.0021914970129728317, 0.004216768313199282, 0.0010552816092967987, 0.0028318525291979313, 0.0008978959522210062, 0.0022240125108510256, 0.004821173846721649, -0.00012342333502601832, 0.0016752611845731735, 0.0023582305293530226, 0.0020930818282067776, -0.002785956021398306, 0.004092060495167971, 0.001065757474862039, 0.00016202160622924566, 0.001466264482587576, -0.005744905211031437, 0.004622707609087229, -0.003389612538740039, -0.0033338884823024273, -0.0021229516714811325, 0.0017200422007590532, -0.004080011509358883, 0.005992039572447538, -0.00041822553612291813, 0.006200084928423166, 0.002892564283683896, -0.005366801284253597, -0.004054903984069824, 0.002935266587883234, -0.0011216215789318085, -0.0002421724930172786, 0.0049160257913172245, 0.0020748022943735123, 0.005709585268050432, -0.005945725366473198, 0.0035000392235815525, 0.0009192018769681454, -0.005741913337260485, 0.0021592024713754654, -0.001449207542464137, -0.0030608256347477436)\n",
      "\n",
      "\n",
      "Slot ID not found - 52682\n"
     ]
    }
   ],
   "source": [
    "embedding_table = [{},{}]\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb') as file:\n",
    "    try:\n",
    "        i = 0\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            print(i, slot_id, key, values)\n",
    "            print(\"\\n\")\n",
    "            i+=1\n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 140400\n",
      "\n",
      "\n",
      "Slot ID not found - 52682\n"
     ]
    }
   ],
   "source": [
    "embedding_table = [{},{}]\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb') as file:\n",
    "    try:\n",
    "        i = 0\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            print(i, slot_id, key)\n",
    "            print(\"\\n\")\n",
    "            i+=1\n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " 0.0,\n",
       " -0.0025734417140483856,\n",
       " -0.00209951214492321,\n",
       " 0.0005660438910126686,\n",
       " -0.0003780214174184948,\n",
       " -0.002427151193842292,\n",
       " 0.0025896215811371803,\n",
       " -0.002583457622677088,\n",
       " -0.0008127631153911352,\n",
       " 0.0009521906031295657,\n",
       " 0.002603534609079361,\n",
       " 0.0013935689348727465,\n",
       " -0.001253835391253233,\n",
       " -0.0006022079032845795,\n",
       " -0.0013171706814318895,\n",
       " 0.0022042200434952974,\n",
       " -0.0013686820166185498,\n",
       " -0.0003645367396529764,\n",
       " 0.0011259124148637056,\n",
       " -0.0016740441787987947,\n",
       " -0.0020831020083278418,\n",
       " 0.0013175222557038069,\n",
       " -0.0012461211299523711,\n",
       " 0.00202497118152678,\n",
       " 0.002086785389110446,\n",
       " -0.00021369877504184842,\n",
       " 0.0009494287078268826,\n",
       " 0.0009641897631809115,\n",
       " -0.0013459889451041818,\n",
       " 0.0012777682859450579,\n",
       " 0.0005965735763311386,\n",
       " -0.0006355794612318277,\n",
       " -0.0005632329266518354,\n",
       " 0.0009067599312402308,\n",
       " 0.0007604279671795666,\n",
       " 0.0002128315099980682,\n",
       " 0.0010227742604911327,\n",
       " 0.0010217636590823531,\n",
       " -0.001789085566997528,\n",
       " -0.0016549587016925216,\n",
       " -0.0007837944431230426,\n",
       " -0.0024296839255839586,\n",
       " -0.0019823710899800062,\n",
       " 0.0016127621056511998,\n",
       " 0.001685733674094081,\n",
       " -0.0014155411627143621,\n",
       " 0.0002874529454857111,\n",
       " -0.0009947494836524129,\n",
       " 0.0003886192571371794,\n",
       " -0.002277058782055974,\n",
       " -0.0024313400499522686,\n",
       " -0.0018285305704921484,\n",
       " -0.0013250362826511264,\n",
       " -0.0008463120320811868,\n",
       " 0.0015077076386660337,\n",
       " 0.0006063278997316957,\n",
       " 0.0007958012283779681,\n",
       " 0.00033522231387905777,\n",
       " 0.0008604289032518864,\n",
       " -0.0012790464097633958,\n",
       " -0.0020509553141891956,\n",
       " -0.002404030878096819,\n",
       " -0.00010126190318260342)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Z\\xe7\\xc2\\xba\\xca\\xcd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x000\\xa7(\\xbb\\xf8\\x97\\t\\xbb\\x90b\\x14:-1\\xc6\\xb9\\xd7\\x10\\x1f\\xbb\\xa4\\xb6);:O)\\xbb\\x9c\\x0fU\\xban\\x9cy:\\x10\\xa0*;j\\xa8\\xb6:\\xbcW\\xa4\\xba}\\xdd\\x1d\\xba\\xea\\xa4\\xac\\xba\\xadt\\x10;Ye\\xb3\\xbaK\\x1f\\xbf\\xb9Z\\x93\\x93:\\x9ak\\xdb\\xba\\xa7\\x84\\x08\\xbb\\xb6\\xb0\\xac:\\xe3T\\xa3\\xbaa\\xb5\\x04;s\\xc2\\x08;T\\x14`\\xb9\\x15\\xe3x:\\xae\\xc1|:\\xe5k\\xb0\\xba\\xcaz\\xa7:`c\\x1c:\\x04\\x9d&\\xba\\xec\\xa5\\x13\\xba\\xa1\\xb3m:uWG:\\x86+_9\\x9c\\x0e\\x86:\\xb3\\xec\\x85:\\xc0\\x7f\\xea\\xba3\\xeb\\xd8\\xba\\x8ewM\\xbaU;\\x1f\\xbb\\xab\\xea\\x01\\xbbQc\\xd3:\\xd6\\xf3\\xdc:\\xae\\x89\\xb9\\xbaH\\xb5\\x969Ab\\x82\\xba\\x98\\xbf\\xcb9\\xb5:\\x15\\xbb\\x1eW\\x1f\\xbbN\\xab\\xef\\xba\\xd7\\xac\\xad\\xba\\n\\xdb]\\xbaF\\x9e\\xc5:\\xfa\\xf1\\x1e:Q\\x9dP:\\xc7\\xc0\\xaf9h\\x8ea:\\xad\\xa5\\xa7\\xbaRi\\x06\\xbb\\xf2\\x8c\\x1d\\xbb\\x92\\\\\\xd4\\xb8'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = file.read(each_key_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "            key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140400"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " -0.0014837137423455715,\n",
       " 0.0035978069063276052,\n",
       " 0.0013369740918278694,\n",
       " 0.003021236741915345,\n",
       " -0.0014232619432732463,\n",
       " -0.0034976580645889044,\n",
       " 0.0013507071416825056,\n",
       " 0.006121872924268246,\n",
       " -0.0016243001446127892,\n",
       " -0.0024449483025819063,\n",
       " -0.004137653857469559,\n",
       " -0.0027854733634740114,\n",
       " -0.0028018211014568806,\n",
       " -0.0025738978292793036,\n",
       " -0.002862881636247039,\n",
       " 0.004320679698139429,\n",
       " -0.0010421797633171082,\n",
       " -0.0022757970727980137,\n",
       " -0.0037264025304466486,\n",
       " -0.0020226924680173397,\n",
       " 0.00015580451872665435,\n",
       " 0.0021914970129728317,\n",
       " 0.004216768313199282,\n",
       " 0.0010552816092967987,\n",
       " 0.0028318525291979313,\n",
       " 0.0008978959522210062,\n",
       " 0.0022240125108510256,\n",
       " 0.004821173846721649,\n",
       " -0.00012342333502601832,\n",
       " 0.0016752611845731735,\n",
       " 0.0023582305293530226,\n",
       " 0.0020930818282067776,\n",
       " -0.002785956021398306,\n",
       " 0.004092060495167971,\n",
       " 0.001065757474862039,\n",
       " 0.00016202160622924566,\n",
       " 0.001466264482587576,\n",
       " -0.005744905211031437,\n",
       " 0.004622707609087229,\n",
       " -0.003389612538740039,\n",
       " -0.0033338884823024273,\n",
       " -0.0021229516714811325,\n",
       " 0.0017200422007590532,\n",
       " -0.004080011509358883,\n",
       " 0.005992039572447538,\n",
       " -0.00041822553612291813,\n",
       " 0.006200084928423166,\n",
       " 0.002892564283683896,\n",
       " -0.005366801284253597,\n",
       " -0.004054903984069824,\n",
       " 0.002935266587883234,\n",
       " -0.0011216215789318085,\n",
       " -0.0002421724930172786,\n",
       " 0.0049160257913172245,\n",
       " 0.0020748022943735123,\n",
       " 0.005709585268050432,\n",
       " -0.005945725366473198,\n",
       " 0.0035000392235815525,\n",
       " 0.0009192018769681454,\n",
       " -0.005741913337260485,\n",
       " 0.0021592024713754654,\n",
       " -0.001449207542464137,\n",
       " -0.0030608256347477436)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_key_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = file.read(each_key_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], buffer[0: 2*key_type_map[key_type][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52682"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3133335386"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 140400\n",
      "\n",
      "\n",
      "Slot ID not found - 52682\n"
     ]
    }
   ],
   "source": [
    "embedding_table = [{},{}]\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb') as file:\n",
    "    try:\n",
    "        i = 0\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            print(i, slot_id, key)\n",
    "            print(\"\\n\")\n",
    "            i+=1\n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "read of closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-5f5e9d428e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_key_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: read of closed file"
     ]
    }
   ],
   "source": [
    "buffer = file.read(each_key_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = file.read(each_key_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'p$\\x02\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00,y\\xc2\\xba/\\xc9k;h=\\xaf:\\xf1\\xffE;\\xbf\\x8c\\xba\\xba\\xf78e\\xbb6\\n\\xb1:\\xfe\\x99\\xc8;x\\xe6\\xd4\\xbam; \\xbb(\\x95\\x87\\xbb}\\x8c6\\xbb\\xc2\\x9e7\\xbb\\xd7\\xae(\\xbb/\\x9f;\\xbb}\\x94\\x8d;\\xc0\\x99\\x88\\xba\\x8a%\\x15\\xbb\\xa96t\\xbb&\\x8f\\x04\\xbbu_#98\\x9f\\x0f;\\xd1,\\x8a;`Q\\x8a:\\x9a\\x969;\\xc7`k:\\xbd\\xc0\\x11;\\xf0\\xfa\\x9d;3k\\x01\\xb9p\\x94\\xdb:\\x8b\\x8c\\x1a;\\x16,\\t;\\x96\\x946\\xbb\\xb1\\x16\\x86;\\xe3\\xb0\\x8b:X\\xe4)9\\xac/\\xc0:\\xc2?\\xbc\\xbb\\x15z\\x97;C$^\\xbb^}Z\\xbb8!\\x0b\\xbb\\ns\\xe1:\\x9e\\xb1\\x85\\xbb\\xdfX\\xc4;HE\\xdb\\xb9\\x15*\\xcb;-\\x91=;\\xfe\\xdb\\xaf\\xbb\\x00\\xdf\\x84\\xbb\\x9a]@;`\\x03\\x93\\xba\\xaf\\xef}\\xb9\\x9d\\x16\\xa1;h\\xf9\\x07;y\\x17\\xbb;\\\\\\xd4\\xc2\\xbb\\xea`e;\\x98\\xf6p:\\xa9&\\xbc\\xbbh\\x81\\r;V\\xf3\\xbd\\xba\"\\x98H\\xbb'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_key_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_key_size = 72*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = file.read(each_key_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, slot_id = struct.unpack(\"2\" + key_type_map[key_type][0], \n",
    "                                         buffer[0: 2*key_type_map[key_type][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140400, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key, slot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "unpack requires a buffer of 256 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-b2d7bf55fc09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_vec_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey_type_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: unpack requires a buffer of 256 bytes"
     ]
    }
   ],
   "source": [
    " values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[2*key_type_map[key_type][1]: ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-86c5c6455680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0membedding_vec_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0meach_key_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_type_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0membedding_vec_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "import struct \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "key_type = 'I32' # {'I64', 'I32'}, default is 'I32'\n",
    "key_type_map = {\"I32\": [\"I\", 4], \"I64\": [\"q\", 8]}\n",
    "\n",
    "embedding_vec_size = 64\n",
    "each_key_size = key_type_map[key_type][1] + 8 + 4 * embedding_vec_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "key_type = 'I32' # {'I64', 'I32'}, default is 'I32'\n",
    "key_type_map = {\"I32\": [\"I\", 4], \"I64\": [\"q\", 8]}\n",
    "\n",
    "embedding_vec_size = 64\n",
    "each_key_size = key_type_map[key_type][1] + 8 + 4 * embedding_vec_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'self' is not defined\n"
     ]
    }
   ],
   "source": [
    "embedding_table = [{},{}]\n",
    "\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb') as file:\n",
    "    try:\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key = struct.unpack(key_type_map[self.key_type][0], buffer[0 : key_type_map[key_type][1]])[0]\n",
    "            slot_id = struct.unpack(\"Q\", buffer[key_type_map[key_type][1] : key_type_map[key_type][1] + 8])[0]\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[key_type_map[key_type][1] + 8: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            \n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_table = [{},{}]\n",
    "\n",
    "with open('./hugeCTR_saved_model_DLRM/0_sparse_9000.model', 'rb') as file:\n",
    "    try:\n",
    "        while True:\n",
    "            buffer = file.read(each_key_size)\n",
    "            if len(buffer) == 0:\n",
    "                break\n",
    "\n",
    "            key = struct.unpack(key_type_map[key_type][0], buffer[0 : key_type_map[key_type][1]])[0]\n",
    "            slot_id = struct.unpack(\"Q\", buffer[key_type_map[key_type][1] : key_type_map[key_type][1] + 8])[0]\n",
    "            values = struct.unpack(str(embedding_vec_size) + \"f\", buffer[key_type_map[key_type][1] + 8: ])\n",
    "\n",
    "            if slot_id==0:\n",
    "                embedding_table[slot_id][key] = values\n",
    "            elif slot_id==1:\n",
    "                embedding_table[slot_id][key - 138493] = values \n",
    "            else:\n",
    "                raise(Exception(\"Slot ID not found - %d\"%slot_id))\n",
    "            \n",
    "    except BaseException as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26744"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_table[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embedding = np.zeros((26744, embedding_vec_size), dtype='float')\n",
    "for i in range(len(embedding_table[1])):\n",
    "    item_embedding[i] = embedding_table[1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def find_similar_movies(nn_movie_id, item_embedding, k=10, metric=\"euclidean\"):\n",
    "    #find the top K similar items according to one of the distance metric: cosine or euclidean\n",
    "    sim = 1-cdist(item_embedding, item_embedding[nn_movie_id].reshape(1, -1), metric=metric)\n",
    "   \n",
    "    return sim.squeeze().argsort()[-k:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./mappings.pickle', 'rb') as handle:\n",
    "    movies_mapping = pickle.load(handle)[\"items\"]\n",
    "\n",
    "nn_to_movies = movies_mapping\n",
    "movies_to_nn = {}\n",
    "for i in range(len(movies_mapping)):\n",
    "    movies_to_nn[movies_mapping[i]] = i\n",
    "\n",
    "import pandas as pd\n",
    "movies = pd.read_csv(\"./data/ml-20m/movies.csv\", index_col=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  Toy Story (1995) Adventure|Animation|Children|Comedy|Fantasy\n",
      "Similar movies: \n",
      "1 Toy Story (1995) Adventure|Animation|Children|Comedy|Fantasy\n",
      "127268 Project Wild Thing (2013) Adventure|Children|Documentary|Drama\n",
      "69448 Promise Me This (Zavet) (2007) Comedy\n",
      "102523 To Be King (Koning van Katoren) (2012) Adventure\n",
      "103602 Craig Ferguson: I'm Here To Help (2013) Comedy|Documentary\n",
      "1999 Exorcist III, The (1990) Horror\n",
      "55851 Crazy Love (2007) Documentary\n",
      "97915 Lookin' to Get Out (1982) Comedy\n",
      "92130 Red Psalm (Még kér a nép) (1972) Drama|Musical|War\n",
      "90203 Tony Arzenta (No Way Out) (Big Guns) (1973) Action|Crime|Drama|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Jumanji (1995) Adventure|Children|Fantasy\n",
      "Similar movies: \n",
      "2 Jumanji (1995) Adventure|Children|Fantasy\n",
      "77189 Desperate Journey (1942) Drama|War\n",
      "7222 Reefer Madness (a.k.a. Tell Your Children) (1938) Comedy|Drama\n",
      "8646 Distant Drums (1951) Action|Romance|Western\n",
      "3030 Yojimbo (1961) Action|Adventure\n",
      "129671 Bomber (2009) Comedy|Drama\n",
      "6180 Q & A (1990) Crime|Drama\n",
      "99946 London After Midnight (2002) Drama|Horror\n",
      "101536 Alabama Moon (2009) Adventure|Children|Drama\n",
      "63828 Confessions of a Superhero (2007) Documentary\n",
      "=================================\n",
      "\n",
      "Query:  Grumpier Old Men (1995) Comedy|Romance\n",
      "Similar movies: \n",
      "3 Grumpier Old Men (1995) Comedy|Romance\n",
      "59018 Visitor, The (2007) Drama|Romance\n",
      "111542 Invaders from Space (1965) Action|Sci-Fi\n",
      "111038 Ten Violent Women (1982) Action|Drama\n",
      "128269 Tyler Perry's A Madea Christmas (2011) Comedy\n",
      "100194 Jim Jefferies: Fully Functional (EPIX) (2012) Comedy\n",
      "44582 City on Fire (Lung fu fong wan) (1987) Action|Crime|Drama|Thriller\n",
      "2961 Story of Us, The (1999) Comedy|Drama\n",
      "5425 Dark Blue World (Tmavomodrý svet) (2001) Drama|War\n",
      "3286 Snow Day (2000) Comedy\n",
      "=================================\n",
      "\n",
      "Query:  Waiting to Exhale (1995) Comedy|Drama|Romance\n",
      "Similar movies: \n",
      "4 Waiting to Exhale (1995) Comedy|Drama|Romance\n",
      "93496 Cencoroll (2009) Action|Animation|Sci-Fi\n",
      "78622 Nekromantik 2 (1991) Horror\n",
      "687 Country Life (1994) Drama|Romance\n",
      "81831 First Beautiful Thing, The (La prima cosa bella) (2010) Comedy|Drama\n",
      "101264 Elevator (2008) Comedy|Drama\n",
      "4209 Rated X (2000) Drama\n",
      "7844 Legend, The (Legend of Fong Sai-Yuk, The) (Fong Sai Yuk) (1993) Action|Comedy\n",
      "104249 Mr. Moto in Danger Island (1939) Crime|Drama|Mystery|Thriller\n",
      "126170 Mercredi, folle journée! (2001) Comedy|Drama\n",
      "=================================\n",
      "\n",
      "Query:  Father of the Bride Part II (1995) Comedy\n",
      "Similar movies: \n",
      "5 Father of the Bride Part II (1995) Comedy\n",
      "1685 I Love You, I Love You Not (1996) Drama|Romance\n",
      "26741 Mannequin 2: On the Move (1991) Comedy|Fantasy|Romance\n",
      "73148 Bridge of Dragons (1999) Action|Romance|Sci-Fi|Thriller\n",
      "110061 Two Queens and One Consort (Twee vorstinnen en een vorst) (1981) Drama\n",
      "4781 Megiddo: The Omega Code 2 (2001) Action|Adventure|Fantasy|Sci-Fi|Thriller\n",
      "103543 Lifeguard, The (2013) Comedy|Drama\n",
      "908 North by Northwest (1959) Action|Adventure|Mystery|Romance|Thriller\n",
      "9013 Secret Honor (1984) Drama\n",
      "39777 Tarzan the Ape Man (1932) Action|Adventure\n",
      "=================================\n",
      "\n",
      "Query:  Heat (1995) Action|Crime|Thriller\n",
      "Similar movies: \n",
      "6 Heat (1995) Action|Crime|Thriller\n",
      "68650 Powder Blue (2009) Drama\n",
      "102943 Feeding Frenzy (2010) Comedy|Horror\n",
      "56336 Wrong Turn 2: Dead End (2007) Action|Horror|Thriller\n",
      "90019 Green Chair (Noksaek uija) (2005) Drama|Romance\n",
      "56367 Juno (2007) Comedy|Drama|Romance\n",
      "165 Die Hard: With a Vengeance (1995) Action|Crime|Thriller\n",
      "120484 Lille Fridolf and I (1956) Comedy\n",
      "89994 Rabbit à la Berlin (Królik po berlinsku) (2009) Documentary|War\n",
      "76143 Bone Man, The (Der Knochenmann) (2009) Crime|Thriller\n",
      "=================================\n",
      "\n",
      "Query:  Sabrina (1995) Comedy|Romance\n",
      "Similar movies: \n",
      "7 Sabrina (1995) Comedy|Romance\n",
      "72958 Mum & Dad (2008) Horror\n",
      "72927 Donkey Xote (2007) Animation\n",
      "109038 Schooled: The Price of College Sports (2013)  Documentary\n",
      "89114 Last Frontier, The (1955) Western\n",
      "80219 Machete (2010) Action|Adventure|Comedy|Crime|Thriller\n",
      "42602 Boys of Baraka, The (2005) Documentary\n",
      "69446 3 on a Couch (Three on a Couch) (1966) Comedy|Romance\n",
      "2890 Three Kings (1999) Action|Adventure|Comedy|Drama|War\n",
      "104345 Back Door to Hell (1964) Drama|War\n",
      "=================================\n",
      "\n",
      "Query:  Tom and Huck (1995) Adventure|Children\n",
      "Similar movies: \n",
      "8 Tom and Huck (1995) Adventure|Children\n",
      "82840 Home Song Stories, The (2007) Drama\n",
      "638 Jack and Sarah (1995) Romance\n",
      "1662 Gang Related (1997) Crime\n",
      "43248 Swamp Women (1956) Adventure|Crime|Horror\n",
      "6920 Cercle Rouge, Le (Red Circle, The) (1970) Crime|Thriller\n",
      "7191 Blame It on the Bellboy (1992) Comedy\n",
      "129951 Rich Hill (2014) Documentary\n",
      "58452 Saving Sarah Cain (2007) Drama\n",
      "86931 This Above All (1942) Drama|Romance|War\n",
      "=================================\n",
      "\n",
      "Query:  Sudden Death (1995) Action\n",
      "Similar movies: \n",
      "9 Sudden Death (1995) Action\n",
      "6161 Painted Fire (Chihwaseon) (2002) Drama\n",
      "31813 Sister Helen (2002)  Documentary\n",
      "86725 We Are What We Are (Somos lo que hay) (2010) Drama|Horror\n",
      "76747 Angel (2007) Drama|Romance\n",
      "1925 Wings (1927) Action|Drama|Romance|War\n",
      "73314 10 MPH (2007) Documentary\n",
      "109207 Super Inframan, The (Zhong guo chao ren) (1975) Action|Fantasy|Sci-Fi\n",
      "1525 Warriors of Virtue (1997) Action|Adventure|Children|Fantasy\n",
      "91617 New Life, A (La vie nouvelle) (2002) Drama\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for movie_ID in range(1,10):\n",
    "    try:\n",
    "        print(\"Query: \", movies.loc[movie_ID][\"title\"], movies.loc[movie_ID][\"genres\"])\n",
    "\n",
    "        print(\"Similar movies: \")\n",
    "        similar_movies = find_similar_movies(movies_to_nn[movie_ID], item_embedding)\n",
    "\n",
    "        for i in similar_movies:\n",
    "            print(nn_to_movies[i], movies.loc[nn_to_movies[i]][\"title\"], movies.loc[nn_to_movies[i]][\"genres\"])\n",
    "        print(\"=================================\\n\")\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
